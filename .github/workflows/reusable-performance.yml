name: Performance Monitoring and Metrics

on:
  workflow_call:
    inputs:
      job-name:
        description: 'Name of the job being monitored'
        required: true
        type: string
      platform:
        description: 'Platform being monitored'
        required: true
        type: string
      build-id:
        description: 'Unique build identifier'
        required: false
        type: string
        default: ''
      metrics:
        description: 'Additional metrics to track'
        required: false
        type: string
        default: ''
    outputs:
      performance-score:
        value: ${{ jobs.performance-monitor.outputs.score }}
      metrics-data:
        value: ${{ jobs.performance-monitor.outputs.metrics }}

jobs:
  performance-monitor:
    name: Monitor Performance for ${{ inputs.job-name }}
    runs-on: ubuntu-latest
    outputs:
      score: ${{ steps.analyzer.outputs.score }}
      metrics: ${{ steps.analyzer.outputs.metrics }}
    steps:
      - name: Start Performance Monitoring
        id: start
        run: |
          START_TIME=$(date +%s)
          echo "monitor_start_time=$START_TIME" >> "$GITHUB_ENV"
          echo "Performance monitoring started at $(date)"

      - name: Collect System Metrics
        id: system-metrics
        run: |
          # Collect system information
          CPU_CORES=$(nproc)
          MEMORY_TOTAL=$(grep MemTotal /proc/meminfo | awk '{print $2}')
          DISK_SPACE=$(df -h . | tail -1 | awk '{print $4}')
          
          echo "cpu_cores=$CPU_CORES" >> "$GITHUB_OUTPUT"
          echo "memory_total_mb=$((MEMORY_TOTAL / 1024))" >> "$GITHUB_OUTPUT"
          echo "disk_space_gb=$DISK_SPACE" >> "$GITHUB_OUTPUT"
          
          echo "System metrics collected:"
          echo "- CPU Cores: $CPU_CORES"
          echo "- Memory: $((MEMORY_TOTAL / 1024)) MB"
          echo "- Disk Space: $DISK_SPACE"

      - name: Monitor Build Performance
        id: build-metrics
        if: always()
        run: |
          END_TIME=$(date +%s)
          START_TIME="${{ env.monitor_start_time }}"
          
          if [ -n "$START_TIME" ]; then
            DURATION=$((END_TIME - START_TIME))
          else
            DURATION=0
          fi
          
          echo "build_duration=$DURATION" >> "$GITHUB_OUTPUT"
          echo "Build duration: ${DURATION} seconds"

      - name: Cache Performance Analysis
        id: cache-analysis
        run: |
          # Analyze cache performance
          CACHE_HIT_RATE=0
          
          # Check if cache was used (this would be enhanced with actual cache metrics)
          if [ -d "$RUNNER_TEMP/_temp/_github_home" ]; then
            CACHE_HIT_RATE=85  # Example value
          fi
          
          echo "cache_hit_rate=$CACHE_HIT_RATE" >> "$GITHUB_OUTPUT"
          echo "Cache hit rate: ${CACHE_HIT_RATE}%"

      - name: Resource Utilization Analysis
        id: resource-analysis
        run: |
          # Analyze resource utilization patterns
          RESOURCE_SCORE=0
          
          CPU_CORES="${{ steps.system-metrics.outputs.cpu_cores }}"
          MEMORY_MB="${{ steps.system-metrics.outputs.memory_total_mb }}"
          
          # Calculate resource utilization score
          if [ "$CPU_CORES" -ge 4 ] && [ "$MEMORY_MB" -ge 8192 ]; then
            RESOURCE_SCORE=90
          elif [ "$CPU_CORES" -ge 2 ] && [ "$MEMORY_MB" -ge 4096 ]; then
            RESOURCE_SCORE=75
          else
            RESOURCE_SCORE=60
          fi
          
          echo "resource_score=$RESOURCE_SCORE" >> "$GITHUB_OUTPUT"
          echo "Resource utilization score: $RESOURCE_SCORE"

      - name: Performance Analyzer
        id: analyzer
        run: |
          # Calculate overall performance score
          BUILD_DURATION="${{ steps.build-metrics.outputs.build_duration }}"
          CACHE_HIT_RATE="${{ steps.cache-analysis.outputs.cache_hit_rate }}"
          RESOURCE_SCORE="${{ steps.resource-analysis.outputs.resource_score }}"
          
          # Performance scoring algorithm
          SCORE=0
          
          # Duration-based scoring (faster is better)
          if [ "$BUILD_DURATION" -lt 300 ]; then
            SCORE=$((SCORE + 40))
          elif [ "$BUILD_DURATION" -lt 600 ]; then
            SCORE=$((SCORE + 30))
          elif [ "$BUILD_DURATION" -lt 1200 ]; then
            SCORE=$((SCORE + 20))
          else
            SCORE=$((SCORE + 10))
          fi
          
          # Cache performance scoring
          SCORE=$((SCORE + CACHE_HIT_RATE / 10))
          
          # Resource utilization scoring
          SCORE=$((SCORE + RESOURCE_SCORE / 10))
          
          # Platform-specific adjustments
          case "${{ inputs.platform }}" in
            "linux")
              SCORE=$((SCORE + 5))
              ;;
            "macos")
              SCORE=$((SCORE + 3))
              ;;
            "windows")
              SCORE=$((SCORE + 2))
              ;;
            "android")
              SCORE=$((SCORE + 4))
              ;;
          esac
          
          # Ensure score is within bounds
          if [ "$SCORE" -gt 100 ]; then
            SCORE=100
          fi
          
          echo "score=$SCORE" >> "$GITHUB_OUTPUT"
          
          # Generate performance metrics JSON
          cat > performance_metrics.json << EOF
          {
            "build_id": "${{ inputs.build-id }}",
            "job_name": "${{ inputs.job-name }}",
            "platform": "${{ inputs.platform }}",
            "timestamp": "$(date -Iseconds)",
            "metrics": {
              "build_duration": $BUILD_DURATION,
              "cache_hit_rate": $CACHE_HIT_RATE,
              "resource_score": $RESOURCE_SCORE,
              "performance_score": $SCORE
            },
            "system": {
              "cpu_cores": $CPU_CORES,
              "memory_mb": $MEMORY_MB,
              "disk_space_gb": "$DISK_SPACE"
            },
            "github": {
              "run_id": "${{ github.run_id }}",
              "job_id": "${{ github.job }}",
              "workflow": "${{ github.workflow }}"
            }
          }
          EOF
          
          echo "metrics=$(cat performance_metrics.json | base64 -w 0)" >> "$GITHUB_OUTPUT"
          
          echo "Performance analysis complete:"
          echo "- Performance Score: $SCORE/100"
          echo "- Build Duration: ${BUILD_DURATION}s"
          echo "- Cache Hit Rate: ${CACHE_HIT_RATE}%"
          echo "- Resource Score: $RESOURCE_SCORE/100"

      - name: Performance Regression Detection
        id: regression
        run: |
          CURRENT_SCORE="${{ steps.analyzer.outputs.score }}"
          
          # Load historical data (would be stored in artifact or external storage)
          if [ -f "performance_history.json" ]; then
            HISTORICAL_AVG=$(jq '.average_score' performance_history.json 2>/dev/null || echo "0")
            
            if [ "$HISTORICAL_AVG" != "0" ]; then
              DIFFERENCE=$((CURRENT_SCORE - HISTORICAL_AVG))
              
              if [ "$DIFFERENCE" -lt "-10" ]; then
                echo "regression_detected=true" >> "$GITHUB_OUTPUT"
                echo "Performance regression detected: ${DIFFERENCE} points"
              else
                echo "regression_detected=false" >> "$GITHUB_OUTPUT"
                echo "No significant performance regression"
              fi
            else
              echo "regression_detected=false" >> "$GITHUB_OUTPUT"
              echo "No historical data available for comparison"
            fi
          else
            echo "regression_detected=false" >> "$GITHUB_OUTPUT"
            echo "No historical data available for comparison"
          fi

      - name: Upload Performance Data
        uses: actions/upload-artifact@v4
        with:
          name: performance-data-${{ inputs.job-name }}-${{ inputs.platform }}
          path: |
            performance_metrics.json
            performance_history.json
          retention-days: 90

      - name: Create Performance Report
        if: always()
        run: |
          SCORE="${{ steps.analyzer.outputs.score }}"
          DURATION="${{ steps.build-metrics.outputs.build_duration }}"
          
          cat > performance_report.md << EOF
          # Performance Report for ${{ inputs.job-name }}
          
          **Build Information:**
          - Job: ${{ inputs.job-name }}
          - Platform: ${{ inputs.platform }}
          - Build ID: ${{ inputs.build-id }}
          - Timestamp: $(date)
          
          **Performance Metrics:**
          - Overall Score: $SCORE/100
          - Build Duration: ${DURATION}s
          - Cache Hit Rate: ${{ steps.cache-analysis.outputs.cache_hit_rate }}%
          - Resource Utilization: ${{ steps.resource-analysis.outputs.resource_score }}/100
          
          **System Information:**
          - CPU Cores: ${{ steps.system-metrics.outputs.cpu_cores }}
          - Memory: ${{ steps.system-metrics.outputs.memory_total_mb }} MB
          - Disk Space: ${{ steps.system-metrics.outputs.disk_space_gb }}
          
          **Performance Grade:**
          EOF
          
          if [ "$SCORE" -ge 90 ]; then
            echo "A+ - Excellent Performance" >> performance_report.md
          elif [ "$SCORE" -ge 80 ]; then
            echo "A - Good Performance" >> performance_report.md
          elif [ "$SCORE" -ge 70 ]; then
            echo "B - Acceptable Performance" >> performance_report.md
          elif [ "$SCORE" -ge 60 ]; then
            echo "C - Needs Improvement" >> performance_report.md
          else
            echo "F - Poor Performance" >> performance_report.md
          fi
          
          cat >> performance_report.md << EOF
          
          **Recommendations:**
          1. Monitor cache hit rates and optimize caching strategy
          2. Consider parallelizing build steps where possible
          3. Review resource allocation for the runner
          4. Analyze build duration trends over time
          5. Implement incremental builds for faster development cycles
          
          **Regression Status:**
          ${{ steps.regression.outputs.regression_detected }}
          EOF

      - name: Update Performance Dashboard
        if: always()
        run: |
          # Create or update performance dashboard
          DASHBOARD_FILE="performance_dashboard.md"
          
          if [ ! -f "$DASHBOARD_FILE" ]; then
            cat > "$DASHBOARD_FILE" << EOF
          # Citron CI/CD Performance Dashboard
          
          ## Overview
          This dashboard tracks the performance of our CI/CD pipelines across different platforms and builds.
          
          ## Latest Performance Metrics
          
          | Build | Platform | Score | Duration | Cache Hit Rate | Timestamp |
          |-------|----------|-------|----------|----------------|-----------|
          EOF
          fi
          
          SCORE="${{ steps.analyzer.outputs.score }}"
          DURATION="${{ steps.build-metrics.outputs.build_duration }}"
          CACHE_RATE="${{ steps.cache-analysis.outputs.cache_hit_rate }}"
          
          # Add new entry to dashboard
          sed -i "/## Latest Performance Metrics/a| ${{ inputs.job-name }} | ${{ inputs.platform }} | $SCORE/100 | ${DURATION}s | ${CACHE_RATE}% | $(date '+%Y-%m-%d %H:%M:%S') |" "$DASHBOARD_FILE"
          
          echo "Performance dashboard updated"

      - name: Performance Alerting
        if: steps.regression.outputs.regression_detected == 'true' || steps.analyzer.outputs.score < 70
        run: |
          SCORE="${{ steps.analyzer.outputs.score }}"
          
          # Send alert for poor performance
          WEBHOOK_URL="${{ secrets.DISCORD_WEBHOOK }}"
          if [ -n "$WEBHOOK_URL" ]; then
            curl -H "Content-Type: application/json" \
                 -d "{\"content\":\"âš ï¸ **Performance Alert**\n\nðŸš¨ **Job:** ${{ inputs.job-name }}\nðŸ“¦ **Platform:** ${{ inputs.platform }}\nðŸ“Š **Score:** $SCORE/100\nâ±ï¸ **Duration:** ${{ steps.build-metrics.outputs.build_duration }}s\nðŸ“… **Time:** $(date)\nðŸ”— **Run:** https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\"}" \
                 "$WEBHOOK_URL"
          fi
          
          echo "Performance alert sent for poor performance"